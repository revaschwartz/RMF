---
date: 01-03-01
title: MAP 3.1
categories:
  - MAP-3
description: Benefits of intended system behavior are examined and documented.
type: Map
order_number: 1
---

{::options parse_block_html="true" /}


<details>
<summary markdown="span">**What is this subcategory about?**</summary>
<br>
AI system benefits should counterbalance the inherent risks and implicit and explicit costs. To identify system benefits, organizations should define and document system purpose and utility, along with foreseeable costs, risks, and negative impacts. Credible justification for anticipated benefits beyond the status quo should be clarified and documented.

</details>

<details>
<summary markdown="span">**How can organizations achieve the outcomes of this subcategory?**</summary>

* Utilize participatory approaches and engage with system end users to evaluate system efficacy and interpretability of AI task output. 
* Incorporate stakeholder feedback about perceived system benefits beyond the status quo. 
* Align system requirements with intended purpose and document decisions. 
* Perform context analysis related to time frame, safety concerns, geographic area, physical environment, ecosystems, social environment, and cultural norms within the intended setting (or conditions that closely approximate the intended setting).

</details>

<details>
<summary markdown="span">**What are the transparency and documentation considerations?**</summary>
<br>
**Transparency Considerations – Key Questions: MAP 3.1**
- Did you communicate the benefits of the AI system to users?
- Did you provide appropriate training material and disclaimers to users on how to adequately use the AI system?
- Did your organization implement a risk management system to address risks involved in deploying the identified AI solution (e.g. personnel risk or changes to commercial objectives)?

**AI Transparency Resources: MAP 3.1**
- Intel.gov: AI Ethics Framework for Intelligence Community  - 2020
- GAO-21-519SP: AI Accountability Framework for Federal Agencies & Other Entities
- Assessment List for Trustworthy AI (ALTAI) - The High-Level Expert Group on AI – 2019

</details>

<details>
<summary markdown="span">**What are some informative references?**</summary>    
<br>
Roel Dobbe, Thomas Krendl Gilbert, and Yonatan Mintz. 2021. Hard choices in artificial intelligence. Artificial Intelligence 300 (14 July 2021), 103555, ISSN 0004-3702. DOI: https://doi.org/10.1016/j.artint.2021.103555

Samir Passi and Solon Barocas. 2019. Problem Formulation and Fairness. In Proceedings of the Conference on Fairness, Accountability, and Transparency (FAT* '19). Association for Computing Machinery, New York, NY, USA, 39–48. https://doi.org/10.1145/3287560.3287567

</details>
